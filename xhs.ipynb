{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入包(PypI)\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scrapy.selector import Selector\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 启动 Chrome 浏览器实例：\n",
    "\n",
    "打开 **terminal**, 下载 Chrome Driver (假的 Google Chrome)\n",
    "\n",
    "```bash\n",
    "brew install chromedriver\n",
    "chmod +x /opt/homebrew/bin/chromedriver\n",
    "```\n",
    "\n",
    "输入以下命令（将 `your Chrome.exe path` 替换为您的 Google Chrome 浏览器路径）：\n",
    "```bash\n",
    "<your Chrome.exe path> --remote-debugging-port=9222 --user-data-dir=\"/Users/<your home folder name>/selenium/AutomationProfile\"\n",
    "```\n",
    "\n",
    "- 请将your Chrome.exe path替换为您的Chrome浏览器所在路径，例如<br>`C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe`\n",
    "- 配置 chromedriver 相关信息，请参考官方文档：[ChromeDriver](https://developer.chrome.com/docs/chromedriver)\n",
    "- 来做个比方， 我的 *terminal command* 会是:\n",
    "\n",
    "/Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome \\\n",
    "  --remote-debugging-port=9222 \\\n",
    "  --user-data-dir=\"/Users/princess/selenium/AutomationProfile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据清洗可能需要使用的方法\n",
    "def extract_number(List):\n",
    "    list_cleaned = []\n",
    "    for x in List:\n",
    "        if x is None or not isinstance(x, str):\n",
    "            list_cleaned.append(None)\n",
    "            continue\n",
    "\n",
    "        # Find all numeric patterns in the string\n",
    "        numbers = re.findall(r'\\d+\\.?\\d*', x)\n",
    "        if numbers:\n",
    "            # Join all found numbers (if multiple numbers are in one string)\n",
    "            number = ''.join(numbers)\n",
    "            list_cleaned.append(number)\n",
    "        else:\n",
    "            list_cleaned.append(None)\n",
    "\n",
    "    return list_cleaned\n",
    "\n",
    "def extract_large_number(List):\n",
    "    list_cleaned = []\n",
    "    for x in List:\n",
    "        if x is None or not isinstance(x, str):\n",
    "            list_cleaned.append(None)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            if '万' in x:\n",
    "                number = x.replace('万', '')\n",
    "                number = float(number) * 10000\n",
    "                number = int(number)\n",
    "            else:\n",
    "                number = int(float(x))\n",
    "            list_cleaned.append(number)\n",
    "        except ValueError:\n",
    "            # If conversion fails, append None or handle accordingly\n",
    "            list_cleaned.append(None)\n",
    "\n",
    "    return list_cleaned\n",
    "\n",
    "def extract_date(List):\n",
    "    list_cleaned = []\n",
    "    for x in List:\n",
    "        date_cleand = None  # Initialize with None\n",
    "        if x is None or not isinstance(x, str):\n",
    "            list_cleaned.append(date_cleand)\n",
    "            continue\n",
    "\n",
    "        match = re.search(r'(\\d{4})-(\\d{2})-(\\d{2})', x)\n",
    "        if match:\n",
    "            date_cleand = match.group(0)\n",
    "        else:\n",
    "            match = re.search(r'(\\d{2})-(\\d{2})', x)\n",
    "            if match:\n",
    "                current_year = datetime.now().year\n",
    "                month, day = match.groups()\n",
    "                date_cleand = f'{current_year}-{month}-{day}'\n",
    "\n",
    "        list_cleaned.append(date_cleand)\n",
    "\n",
    "    return list_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置Chrome浏览器\n",
    "service = Service(\"/opt/homebrew/bin/chromedriver\")\n",
    "\n",
    "options = Options()\n",
    "options.add_experimental_option('debuggerAddress', '127.0.0.1:9222')# 远程调控模式启用\n",
    "options.add_argument('--incognito')# 隐身/无痕模式启用\n",
    "browser = webdriver.Chrome(service=service, options=options)\n",
    "action = ActionChains(browser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "即将开始检查小红书登录状态...\n",
      "爬取数据有账户封禁的风险，建议使用非主账号登录。\n",
      "暂未登录，请手动登录\n",
      "检查时间: Wed Dec  4 18:35:11 2024\n",
      "暂未登录，请手动登录\n",
      "检查时间: Wed Dec  4 18:35:21 2024\n",
      "暂未登录，请手动登录\n",
      "检查时间: Wed Dec  4 18:35:31 2024\n",
      "登录成功\n",
      "检查时间: Wed Dec  4 18:35:41 2024\n",
      "请在文本框中根据提示输入搜索关键词和笔记爬取数量。\n",
      "即将开始检查网页加载状态...\n",
      "如果网页进入人机验证页面，请先手动完成验证。\n",
      "加载成功\n",
      "检查时间: Wed Dec  4 18:35:53 2024\n"
     ]
    }
   ],
   "source": [
    "key_word = \"\"\n",
    "num = 0\n",
    "\n",
    "def check_login_status(browser):\n",
    "    print(\"即将开始检查小红书登录状态...\")\n",
    "    print(\"爬取数据有账户封禁的风险，建议使用非主账号登录。\")\n",
    "    \n",
    "    while True:\n",
    "        page_source = browser.page_source\n",
    "        if '登录探索更多内容' in page_source:\n",
    "            print('暂未登录，请手动登录')\n",
    "            print('检查时间:', time.ctime())\n",
    "            time.sleep(10)\n",
    "        else:\n",
    "            print('登录成功')\n",
    "            print('检查时间:', time.ctime())\n",
    "            time.sleep(3)\n",
    "            break\n",
    "\n",
    "def check_page_load_status(browser, keyword):\n",
    "    print(\"即将开始检查网页加载状态...\")\n",
    "    print(\"如果网页进入人机验证页面，请先手动完成验证。\")\n",
    "    \n",
    "    while True:\n",
    "        if keyword in browser.title:\n",
    "            print('加载成功')\n",
    "            print('检查时间:', time.ctime())\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(2)\n",
    "\n",
    "def selenium_test():\n",
    "    \"\"\"\n",
    "    登录状态检查，网页加载检查，根据用户输入进行搜索\n",
    "    \"\"\"\n",
    "    global key_word, num\n",
    "    browser.get('https://www.xiaohongshu.com/explore')\n",
    "    \n",
    "    check_login_status(browser)\n",
    "    \n",
    "    print(\"请在文本框中根据提示输入搜索关键词和笔记爬取数量。\")\n",
    "    keyword = input(\"搜索关键词：\")\n",
    "    try:\n",
    "        num = int(input(\"笔记爬取数量：\"))\n",
    "    except ValueError:\n",
    "        print(\"请输入有效的整数作为爬取数量。\")\n",
    "        return\n",
    "    \n",
    "    url = f'https://www.xiaohongshu.com/search_result?keyword={keyword}&source=web_explore_feed'\n",
    "    browser.get(url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    check_page_load_status(browser, keyword)\n",
    "\n",
    "selenium_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已自动更改模式为图文。\n",
      "请选择排序方式:\n",
      "1. 综合\n",
      "2. 最新\n",
      "3. 最热\n",
      "请输入有效的排序方式...\n"
     ]
    }
   ],
   "source": [
    "def change_mode(browser):\n",
    "    # 更改模式为图文\n",
    "    try:\n",
    "        mode_button = browser.find_element(By.XPATH, '//*[@id=\"search-type\"]/div/div/div[2]')\n",
    "        mode_button.click()\n",
    "        print('已自动更改模式为图文。')\n",
    "    except Exception as e:\n",
    "        print(f\"更改模式失败: {e}\")\n",
    "\n",
    "selected_order_text = ''\n",
    "def change_sort_order(browser, action):\n",
    "    # 更改排序方式\n",
    "    sort_order = {\n",
    "        '综合': 1,\n",
    "        '最新': 2,\n",
    "        '最热': 3\n",
    "    }\n",
    "    print(\"请选择排序方式:\")\n",
    "    for idx, order in sort_order.items():\n",
    "        print(f'{order}. {idx}')\n",
    "    \n",
    "    try:\n",
    "        global selected_order_text\n",
    "        selected_order_text = input(\"请输入排序方式对应的名称: \").strip()\n",
    "        if selected_order_text not in sort_order:\n",
    "            print(\"请输入有效的排序方式...\")\n",
    "            return\n",
    "        \n",
    "        selected_order_index = sort_order[selected_order_text]\n",
    "    except Exception as e:\n",
    "        print(f\"处理排序选择时出错: {e}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        element = browser.find_element(By.XPATH, '//*[@id=\"global\"]/div[2]/div[2]/div/div[1]/div[2]')\n",
    "        action.move_to_element(element).perform()# 模拟鼠标悬停\n",
    "        menu = browser.find_element(By.CLASS_NAME, 'dropdown-items')\n",
    "        option = menu.find_element(By.XPATH, f'/html/body/div[4]/div/li[{selected_order_index}]')\n",
    "        option.click()# 模拟鼠标点击\n",
    "\n",
    "        print('已选择排序方式为:',selected_order_text)\n",
    "        print('检查时间:',time.ctime())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"更改排序方式失败: {e}\")\n",
    "\n",
    "change_mode(browser)\n",
    "change_sort_order(browser, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "已获取的笔记数量...:   6%|▌         | 6/100 [00:54<14:18,  9.13s/it]\n"
     ]
    }
   ],
   "source": [
    "def parsePage(html_content, authorName_list, likeNr_list, URL_list, userURL_list, num):\n",
    "    \"\"\"\n",
    "    解析网页内容并更新数据列表。\n",
    "\n",
    "    Args:\n",
    "        html_content (str): 当前页面的HTML内容\n",
    "        authorName_list (list): 存储作者名字的列表\n",
    "        likeNr_list (list): 存储获赞数量的列表\n",
    "        URL_list (list): 存储笔记URL的列表\n",
    "        userURL_list (list): 存储用户URL的列表\n",
    "        qbar (tqdm): 进度条对象\n",
    "        num (int): 需要爬取的笔记数量\n",
    "\n",
    "    Returns:\n",
    "        None: 数据存储在传入的列表中\n",
    "    \"\"\"\n",
    "    response = Selector(text=html_content)\n",
    "    divs = response.xpath('//div[contains(@class, \"feeds-container\")]/section/div')# 选中网页中包含笔记信息的部分\n",
    "\n",
    "    # 遍历divs获取每一篇笔记的信息\n",
    "    for div in divs:\n",
    "        if len(URL_list) >= num:\n",
    "            break\n",
    "        \n",
    "        if div.xpath('.//span[contains(text(), \"大家都在搜\")]'):\n",
    "            continue\n",
    "\n",
    "        # 选择并提取网页数据\n",
    "        try:\n",
    "            author_name = div.xpath('.//a[contains(@class, \"author\")]/span[contains(@class, \"name\")]/text()').get()# 作者名字\n",
    "            like_nr = div.xpath('.//span[contains(@class, \"count\")]/text()').get()# 获赞数量\n",
    "            url = div.xpath('.//a[contains(@class, \"cover\")]/@href').get()# 笔记URL\n",
    "            user_url = div.xpath('.//a[contains(@class, \"author\")]/@href').get()# 用户URL\n",
    "            \n",
    "            authorName_list.append(author_name)\n",
    "            likeNr_list.append(like_nr)\n",
    "            URL_list.append(url)\n",
    "            userURL_list.append(user_url)\n",
    "\n",
    "            time.sleep(0.35)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return True\n",
    "\n",
    "authorName_list, likeNr_list, URL_list, userURL_list = [], [], [], []\n",
    "qbar = tqdm(total=num, desc=\"已获取的笔记数量...\")\n",
    "\n",
    "# 检查是否已经爬取足够数量的笔记，或是否已经达到页面底部\n",
    "while len(URL_list) < num:\n",
    "    if '- THE END -' in browser.page_source:\n",
    "        print(f\"当前与{key_word}有关的笔记数量少于 {num}\")\n",
    "        print('检查时间:',time.ctime())\n",
    "        break\n",
    "    \n",
    "    parsePage(browser.page_source, authorName_list, likeNr_list, URL_list, userURL_list, num)\n",
    "    qbar.update(1)\n",
    "\n",
    "    if len(URL_list) < num:\n",
    "        browser.execute_script('window.scrollTo(0,document.body.scrollHeight)')# 模拟鼠标滚动\n",
    "        time.sleep(random.uniform(3, 5))\n",
    "\n",
    "if len(URL_list) > num:\n",
    "    URL_list = URL_list[:num]\n",
    "    authorName_list = authorName_list[:num]\n",
    "    likeNr_list = likeNr_list[:num]\n",
    "    userURL_list = userURL_list[:num]\n",
    "\n",
    "qbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有属性列表长度均为 100，爬取成功！\n",
      "检查时间: Wed Dec  4 18:37:33 2024\n"
     ]
    }
   ],
   "source": [
    "if all(len(lst) == num for lst in [authorName_list, likeNr_list, URL_list, userURL_list]):\n",
    "    print(f\"所有属性列表长度均为 {num}，爬取成功！\")\n",
    "    print(f'检查时间: {time.ctime()}')\n",
    "else:\n",
    "    min_length = min(map(len, [authorName_list, likeNr_list, URL_list, userURL_list]))\n",
    "    print(f\"当前属性列表长度最小值为 {min_length}，请重新运行上一代码单元，直至所有属性列表长度均为 {num}！\")\n",
    "    print(f'检查时间: {time.ctime()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下为清洁数据示例:\n",
      "\n",
      "author_name: 小红薯63DFCF89\n",
      "like_nr: 1496\n",
      "url: /66aa25260000000027012206?xsec_token=ABc2hOAUpWxxUOTRDPNHSViag9ouMHngyKceB-ZH23ACM=&xsec_source=\n",
      "user_url: 66aa25260000000027012206?xsec_token=ABc2hOAUpWxxUOTRDPNHSViag9ouMHngyKceB-ZH23ACM=&xsec_source=\n",
      "------\n",
      "author_name: 卡司特高端留学\n",
      "like_nr: 728\n",
      "url: /65e05d7d000000000400320b?xsec_token=ABeiFCyZZMzFmYod2vKcN3x-6hTtIC6tOMluypDdq9tWk=&xsec_source=\n",
      "user_url: 65e05d7d000000000400320b?xsec_token=ABeiFCyZZMzFmYod2vKcN3x-6hTtIC6tOMluypDdq9tWk=&xsec_source=\n",
      "------\n",
      "author_name: 姜姜说留学\n",
      "like_nr: 51\n",
      "url: /671f9138000000002401960e?xsec_token=ABN-deT_NSW6qbk2S61WV6ORlsqnPfvAg7nhUjyvIh-1E=&xsec_source=\n",
      "user_url: 671f9138000000002401960e?xsec_token=ABN-deT_NSW6qbk2S61WV6ORlsqnPfvAg7nhUjyvIh-1E=&xsec_source=\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "likeNr_list = extract_large_number(likeNr_list)\n",
    "URL_list = [re.sub(r'^/search_result/', '/', url) if url is not None else '' for url in URL_list]\n",
    "userURL_list = [url.split('/')[-1] if url is not None else '' for url in URL_list]\n",
    "\n",
    "print(\"以下为清洁数据示例:\\n\")\n",
    "for i in range(3):\n",
    "    print(\"author_name:\", authorName_list[i])\n",
    "    print(\"like_nr:\", likeNr_list[i])\n",
    "    print(\"url:\", URL_list[i])\n",
    "    print(\"user_url:\", userURL_list[i])\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "已获取的笔记数量...: 100%|██████████| 100/100 [07:20<00:00,  4.41s/it]\n"
     ]
    }
   ],
   "source": [
    "def parse_note_page(browser, url, commentNr_list, content_list, datePublished_list, images_list, starNr_list):\n",
    "    \"\"\"\n",
    "    解析单个笔记页面并提取所需数据\n",
    "    \n",
    "    Args:\n",
    "        browser: Selenium WebDriver 实例，用于获取页面内容\n",
    "        url: 笔记的URL\n",
    "        commentNr_list (list): 存储评论数量的列表\n",
    "        content_list (list): 存储笔记内容的列表\n",
    "        datePublished_list (list): 存储发布时间的列表\n",
    "        images_list (list): 存储图片链接的列表\n",
    "        starNr_list (list): 存储收藏数量的列表\n",
    "\n",
    "    Returns:\n",
    "        None: 将提取的数据添加到相应的列表中\n",
    "    \"\"\"\n",
    "    whole_url = 'https://www.xiaohongshu.com/explore' + url# 构造完整笔记URL\n",
    "    browser.get(whole_url)\n",
    "    WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@name=\"description\"]')))# 等待页面加载完成\n",
    "    html = browser.page_source\n",
    "    selector = Selector(text = html)\n",
    "    \n",
    "    try:\n",
    "        # 选择并提取网页数据\n",
    "        comment_nr = selector.xpath('//*[@class=\"total\"]/text()').extract_first()# 评论数量\n",
    "        content = selector.xpath('//*[@name=\"description\"]/@content').extract_first()# 内容\n",
    "        datePublished = selector.xpath('//*[@class=\"date\"]/text()').extract_first()# 发布时间\n",
    "        images = selector.xpath('//*[@name=\"og:image\"]/@content').extract_first()# 图片\n",
    "        images = images + '.jpg' if images else None# 追加图片链接\n",
    "        star_nr = selector.xpath('//*[@class=\"count\"]/text()').extract_first()# 收藏数量\n",
    "\n",
    "        commentNr_list.append(comment_nr)\n",
    "        content_list.append(content)\n",
    "        datePublished_list.append(datePublished)\n",
    "        images_list.append(images)\n",
    "        starNr_list.append(star_nr)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "commentNr_list, content_list, datePublished_list, images_list, starNr_list = [], [], [], [], []\n",
    "\n",
    "qbar = tqdm(total=len(URL_list), desc=\"已获取的笔记数量...\")\n",
    "for url in URL_list:\n",
    "    parse_note_page(browser, url, commentNr_list, content_list, datePublished_list, images_list, starNr_list)\n",
    "    qbar.update(1)\n",
    "    time.sleep(random.uniform(0.5, 2))\n",
    "\n",
    "qbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有属性列表长度均为 100，爬取成功！\n",
      "检查时间: Wed Dec  4 18:45:01 2024\n"
     ]
    }
   ],
   "source": [
    "if all(len(lst) == num for lst in [commentNr_list, content_list, datePublished_list, images_list, starNr_list]):\n",
    "    print(f\"所有属性列表长度均为 {num}，爬取成功！\")\n",
    "    print(f'检查时间: {time.ctime()}')\n",
    "else:\n",
    "    min_length = min(map(len, [commentNr_list, content_list, datePublished_list, images_list, starNr_list]))\n",
    "    print(f\"当前属性列表长度最小值为 {min_length}，请重新运行上一代码单元，直至所有属性列表长度均为 {num}！\")\n",
    "    print(f'检查时间: {time.ctime()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下为清洁数据示例:\n",
      "\n",
      "comment_nr: None\n",
      "content: 留学商科专业选择，关键在于了解自己的兴趣所在，并找到与之匹配的大方向。这样，选校过程就能更加gao效❗ . 定量组：如果你擅长数学和编程，这些专业可能适合你。 1.金融科技(Fintech)：结合金融知识和计算机技能，是金融行业的新宠。 2.金融工程(Financial Engineering)：金融、数学、物理或工程学背景的你，将进修高等数学和概率论等课程。 3.金融(Finance)：强调定量分析能力，经济学和会计等课程是基础。 4.精算(Actuarial Science)：数学或统计学背景，加上jie决问题的能力，是精算师的必备。 5.信息系统管理(Management Information Systems)：计算机科学或管理学背景，将助你掌握数据库管理和信息系统设计。 6.商业分析(Business Analytics)：统计学和数据分析能力，是商业分析领域的基石。 . 传统商科：如果你对商业运作和管理有兴趣，以下专业可能适合你。 1.管理(Management)：了解基本管理原理和组织行为，是成为优质管理者的起点。 2.会计(Accounting)：商业或会计背景，加上财务管理和审计原理的学习，是会计专业的核心。 . 软专业组：如果你的强项在于沟通和人际交往，这些专业可能更适合你。 1.市场营销(Marketing)：营销和沟通能力，加上市场研究和消费者行为学的学习，是市场营销专业的关键。 2.供应链管理(Supply Chain Management)：物流和运营管理背景，将帮助你掌握项目管理技能。 3.人力资源(Human Resources)：管理、心理学或社会学背景，加上组织行为学和劳动法的学习，是人力资源管理的基础。 4.国际商务(International Business)：商业、管理学或国际关系背景，加上国际贸易和quan球市场营销的学习，是国际商务专业的核心。 . 选择专业时，记得考虑自己的兴趣和背景，这样你的留学之路才能更加顺畅。别忘了，适合自己的才是zui好的！ #商科 #商科留学 #商科硕士 #留学申请季 #留学干货 #留学 #留学申请指南\n",
      "datePublished: 2024-07-31\n",
      "images: http://sns-webpic-qc.xhscdn.com/202412050737/a8a896f59862c7d95fd7e7474354162d/1040g2sg315tr8oaigs005ouv9mrpt30fu1to9u0!nd_dft_wlteh_webp_3.jpg\n",
      "star_nr: 1\n",
      "------\n",
      "comment_nr: 57\n",
      "content: 2024QS商科硕士专业排名已出炉，摘录了金融、管理、商业分析、市场营销四大专业，给大家简单捋了一下 · PS：这里只选取了主流英语系国家的院校Top15 · 🌟金融 Finance🌟 · 最强王者：牛津大学、伦敦商学院、麻省理工学院 永恒钻石：加州大学伯克利分校、剑桥大学、伦敦政治经济学院 尊贵铂金：加州大学洛杉矶分校、帝国理工学院、多伦多大学 荣耀黄金：华威大学、麦吉尔大学、曼彻斯特大学 秩序白银：德克萨斯大学奥斯汀分校、爱丁堡大学、南加州大学 · 🌟市场营销 Marketing🌟 · 👑最强王者： 帝国理工学院、哥伦比亚大学、华威大学 💎永恒钻石： 维也纳经济贸易大学、曼彻斯特大学、德克萨斯大学奥斯汀分校 💰尊贵铂金： 爱丁堡大学、南加州大学、克兰菲尔德大学 🏅️荣耀黄金： 明尼苏达大学、利兹大学、密歇根州立大学 🥈秩序白银： 麦考瑞大学、普渡大学、德州农工大学 · 🌟管理 Management🌟 · 最强王者： 伦敦商学院、弗吉尼亚大学、维也纳经济贸易大学 永恒钻石： 帝国理工学院、伦敦政治经济学院、华威大学 尊贵铂金： 密歇根大学 、杜克大学、曼彻斯特大学 荣耀黄金： 悉尼大学、克兰菲尔德大学、爱丁堡大学 秩序白银： 不列颠哥伦比亚大学、波士顿大学、香港科技大学 · 🌟商业分析 Business Analytics🌟 · 👑最强王者： 加州大学洛杉矶分校、麻省理工学院、杜克大学 💎永恒钻石： 帝国理工学院、德克萨斯大学奥斯汀分校、新加坡国立大学 💰尊贵铂金：南加州大学、多伦多大学、麦吉尔大学 🏅️荣耀黄金： 华威大学、墨尔本大学、华盛顿大学 🥈秩序白银： 曼彻斯特大学、普渡大学 、爱丁堡大学 · 商科类QS前100直录通道已开启，后台留下你的预算和想去的国家和地区，可🆓规划 \t #写出你想去的大学 #商科留学 #商科 #世界大学排名 #商业分析 #市场营销 #管理 #硕士申请 #金融专业硕士\n",
      "datePublished: 2024-03-20\n",
      "images: http://sns-webpic-qc.xhscdn.com/202412050737/45ff9130e19b78ba8d8f0bfaccffebaa/1040g2sg30vopl0ouls605pdv9js3bia5gt8sss8!nd_dft_wlteh_webp_3.jpg\n",
      "star_nr: 1\n",
      "------\n",
      "comment_nr: 6\n",
      "content: 根据美国劳工统计局的数据，STEM专业带动的工作岗位，其增长速度和薪酬水平均在美国就业市场处于领先地位（STEM硕士项目的毕业生，可延长他们的选择性实习培训（OPT）至36个月）。 \t 1年制的STEM硕士项目时间短🥰，留学成.本也相对较低。 \t 👇下面，为大家整理了2025美国名校1年制STEM商科/泛商科硕士项目及申请要求，感兴趣的同学可做参考。 \t 哥伦比亚大学 约翰霍普金斯大学 圣路易斯华盛顿大学 密歇根大学安娜堡分校 南加州大学 德州大学奥斯汀分校 东北大学 \t 💪🏻美国一年制STEM硕士，相比2年制硕士，时长、费用均砍半。可谓将成.本降到蕞低，就业力拉到蕞高，简直是性价比天.花板！太值得留子们冲了! - ✨而且就业面更广、起薪更高、拿绿卡更容易！STEM项目的中国留学生平均薪资可达到560,000至5100,000之间 \t 具体申请要求、学费、学制看图文哦 👉需要了解美国一年制商科硕士申请的，留1 \t #美国留学申请 #25fall美国留学 #美国硕士留学 #留学美国 #美国一年制硕士申请条件 #美国一年制硕士留学 #美国一年制商科硕士 #美国一年制硕士 #一年制商科 #商科留学\n",
      "datePublished: 2024-10-28\n",
      "images: http://sns-webpic-qc.xhscdn.com/202412050737/e7bef4d6ae1af5495dc96a9ff5af1c8d/1040g008319ggn0klmq6g5pjrk8fgu2ibjp78bto!nd_dft_wlteh_webp_3.jpg\n",
      "star_nr: 1\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "commentNr_list = extract_large_number(extract_number(commentNr_list))\n",
    "starNr_list = extract_large_number(starNr_list)\n",
    "datePublished_list = extract_date(datePublished_list)\n",
    "\n",
    "print(\"以下为清洁数据示例:\\n\")\n",
    "for i in range(3):\n",
    "    print(\"comment_nr:\", commentNr_list[i])\n",
    "    print(\"content:\", content_list[i])\n",
    "    print(\"datePublished:\", datePublished_list[i])\n",
    "    print(\"images:\", images_list[i])\n",
    "    print(\"star_nr:\", starNr_list[i])\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "已爬取的作者数量...:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: \nStacktrace:\n0   chromedriver                        0x0000000105331548 cxxbridge1$str$ptr + 3618920\n1   chromedriver                        0x0000000105329d98 cxxbridge1$str$ptr + 3588280\n2   chromedriver                        0x0000000104d989c4 cxxbridge1$string$len + 89228\n3   chromedriver                        0x0000000104ddcda8 cxxbridge1$string$len + 368752\n4   chromedriver                        0x0000000104e1654c cxxbridge1$string$len + 604180\n5   chromedriver                        0x0000000104dd15c0 cxxbridge1$string$len + 321672\n6   chromedriver                        0x0000000104dd2210 cxxbridge1$string$len + 324824\n7   chromedriver                        0x00000001052fd4bc cxxbridge1$str$ptr + 3405788\n8   chromedriver                        0x00000001053007dc cxxbridge1$str$ptr + 3418876\n9   chromedriver                        0x00000001052e4130 cxxbridge1$str$ptr + 3302480\n10  chromedriver                        0x000000010530109c cxxbridge1$str$ptr + 3421116\n11  chromedriver                        0x00000001052d5888 cxxbridge1$str$ptr + 3242920\n12  chromedriver                        0x000000010531a9c8 cxxbridge1$str$ptr + 3525864\n13  chromedriver                        0x000000010531ab44 cxxbridge1$str$ptr + 3526244\n14  chromedriver                        0x0000000105329a0c cxxbridge1$str$ptr + 3587372\n15  libsystem_pthread.dylib             0x000000018fc932e4 _pthread_start + 136\n16  libsystem_pthread.dylib             0x000000018fc8e0fc thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m qbar \u001b[38;5;241m=\u001b[39m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(userURL_list), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m已爬取的作者数量...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user_url \u001b[38;5;129;01min\u001b[39;00m userURL_list:\n\u001b[0;32m---> 51\u001b[0m     \u001b[43mparse_author_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbrowser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthorCollectNr_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthorFansNr_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthorNoteNr_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     qbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     53\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(random\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n",
      "Cell \u001b[0;32mIn[12], line 30\u001b[0m, in \u001b[0;36mparse_author_page\u001b[0;34m(browser, user_url, authorCollectNr_list, authorFansNr_list, authorNoteNr_list)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     previous_page_height \u001b[38;5;241m=\u001b[39m current_page_height\n\u001b[0;32m---> 30\u001b[0m \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbrowser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpresence_of_element_located\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m//*[@id=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muserPostedFeeds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m]//section\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m# 等待页面加载完成\u001b[39;00m\n\u001b[1;32m     31\u001b[0m html \u001b[38;5;241m=\u001b[39m browser\u001b[38;5;241m.\u001b[39mpage_source\n\u001b[1;32m     32\u001b[0m selector \u001b[38;5;241m=\u001b[39m Selector(text\u001b[38;5;241m=\u001b[39mhtml)\n",
      "File \u001b[0;32m~/anaconda3/envs/xiaoliu/lib/python3.12/site-packages/selenium/webdriver/support/wait.py:105\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll)\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[0;31mTimeoutException\u001b[0m: Message: \nStacktrace:\n0   chromedriver                        0x0000000105331548 cxxbridge1$str$ptr + 3618920\n1   chromedriver                        0x0000000105329d98 cxxbridge1$str$ptr + 3588280\n2   chromedriver                        0x0000000104d989c4 cxxbridge1$string$len + 89228\n3   chromedriver                        0x0000000104ddcda8 cxxbridge1$string$len + 368752\n4   chromedriver                        0x0000000104e1654c cxxbridge1$string$len + 604180\n5   chromedriver                        0x0000000104dd15c0 cxxbridge1$string$len + 321672\n6   chromedriver                        0x0000000104dd2210 cxxbridge1$string$len + 324824\n7   chromedriver                        0x00000001052fd4bc cxxbridge1$str$ptr + 3405788\n8   chromedriver                        0x00000001053007dc cxxbridge1$str$ptr + 3418876\n9   chromedriver                        0x00000001052e4130 cxxbridge1$str$ptr + 3302480\n10  chromedriver                        0x000000010530109c cxxbridge1$str$ptr + 3421116\n11  chromedriver                        0x00000001052d5888 cxxbridge1$str$ptr + 3242920\n12  chromedriver                        0x000000010531a9c8 cxxbridge1$str$ptr + 3525864\n13  chromedriver                        0x000000010531ab44 cxxbridge1$str$ptr + 3526244\n14  chromedriver                        0x0000000105329a0c cxxbridge1$str$ptr + 3587372\n15  libsystem_pthread.dylib             0x000000018fc932e4 _pthread_start + 136\n16  libsystem_pthread.dylib             0x000000018fc8e0fc thread_start + 8\n"
     ]
    }
   ],
   "source": [
    "def parse_author_page(browser, user_url, authorCollectNr_list, authorFansNr_list, authorNoteNr_list):\n",
    "    \"\"\"\n",
    "    解析单个用户页面并提取所需数据\n",
    "    \n",
    "    Args:\n",
    "        browser: Selenium WebDriver 实例，用于获取页面内容\n",
    "        user_url: 用户的URL\n",
    "        authorCollectNr_list (list): 存储作者获赞与收藏数量的列表\n",
    "        authorFansNr_list (list): 存储作者粉丝数量的列表\n",
    "        authorNoteNr_list (list): 存储作者笔记数量的列表\n",
    "    \n",
    "    Returns:\n",
    "        None: 将提取的数据添加到相应的列表中\n",
    "    \"\"\"\n",
    "\n",
    "    whole_url = 'https://www.xiaohongshu.com/user/profile/' + user_url# 构造完整用户页面URL\n",
    "    browser.get(whole_url)\n",
    "\n",
    "    # 模拟滚动页面直到加载完成\n",
    "    while True:\n",
    "        previous_page_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")# 滚动到页面底部\n",
    "        time.sleep(random.uniform(1, 2))\n",
    "\n",
    "        current_page_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        if current_page_height == previous_page_height:\n",
    "            break\n",
    "        previous_page_height = current_page_height\n",
    "\n",
    "    WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"userPostedFeeds\"]//section')))# 等待页面加载完成\n",
    "    html = browser.page_source\n",
    "    selector = Selector(text=html)\n",
    "\n",
    "    try:\n",
    "        # 选择并提取网页数据\n",
    "        author_collect_nr = selector.xpath('//*[@class=\"data-info\"]/div[1]/div[3]/span[@class=\"count\"]/text()').extract_first()# 作者获赞与收藏数量\n",
    "        author_fans_nr = selector.xpath('//*[@class=\"data-info\"]/div[1]/div[2]/span[@class=\"count\"]/text()').extract_first()# 作者粉丝数量\n",
    "        author_note_nr = len(selector.xpath('//*[@id=\"userPostedFeeds\"]//section'))# 作者笔记数量\n",
    "\n",
    "        authorCollectNr_list.append(author_collect_nr)\n",
    "        authorFansNr_list.append(author_fans_nr)\n",
    "        authorNoteNr_list.append(author_note_nr)\n",
    "\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "authorCollectNr_list, authorFansNr_list, authorNoteNr_list = [], [], []\n",
    "\n",
    "qbar = tqdm(total=len(userURL_list), desc=\"已爬取的作者数量...\")\n",
    "for user_url in userURL_list:\n",
    "    parse_author_page(browser, user_url, authorCollectNr_list, authorFansNr_list, authorNoteNr_list)\n",
    "    qbar.update(1)\n",
    "    time.sleep(random.uniform(1, 2))\n",
    "\n",
    "qbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前属性列表长度最小值为 0，请重新运行上一代码单元，直至所有属性列表长度均为 100！\n",
      "检查时间: Wed Dec  4 18:45:28 2024\n"
     ]
    }
   ],
   "source": [
    "if all(len(lst) == num for lst in [authorCollectNr_list, authorFansNr_list, authorNoteNr_list]):\n",
    "    print(f\"所有属性列表长度均为 {num}，爬取成功！\")\n",
    "    print(f'检查时间: {time.ctime()}')\n",
    "else:\n",
    "    min_length = min(map(len, [authorCollectNr_list, authorFansNr_list, authorNoteNr_list]))\n",
    "    print(f\"当前属性列表长度最小值为 {min_length}，请重新运行上一代码单元，直至所有属性列表长度均为 {num}！\")\n",
    "    print(f'检查时间: {time.ctime()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下为清洁数据示例：\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m以下为清洁数据示例：\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor_collect_nr:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mauthorCollectNr_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor_fans_nr:\u001b[39m\u001b[38;5;124m\"\u001b[39m, authorFansNr_list[i])\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor_note_nr:\u001b[39m\u001b[38;5;124m\"\u001b[39m, authorNoteNr_list[i])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "authorCollectNr_list = extract_large_number(authorCollectNr_list)\n",
    "authorFansNr_list = extract_large_number(authorFansNr_list)\n",
    "\n",
    "print(\"以下为清洁数据示例：\")\n",
    "for i in range(3):\n",
    "    print(\"author_collect_nr:\", authorCollectNr_list[i])\n",
    "    print(\"author_fans_nr:\", authorFansNr_list[i])\n",
    "    print(\"author_note_nr:\", authorNoteNr_list[i])\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "删除 10 行重复行后剩余 90 行。\n",
      "检查时间: Wed Dec  4 18:45:32 2024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_name</th>\n",
       "      <th>comment_nr</th>\n",
       "      <th>content</th>\n",
       "      <th>datePublished</th>\n",
       "      <th>images</th>\n",
       "      <th>like_nr</th>\n",
       "      <th>star_nr</th>\n",
       "      <th>url</th>\n",
       "      <th>user_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>小红薯63DFCF89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>留学商科专业选择，关键在于了解自己的兴趣所在，并找到与之匹配的大方向。这样，选校过程就能更加...</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>http://sns-webpic-qc.xhscdn.com/202412050737/a...</td>\n",
       "      <td>1496.0</td>\n",
       "      <td>1</td>\n",
       "      <td>/66aa25260000000027012206?xsec_token=ABc2hOAUp...</td>\n",
       "      <td>66aa25260000000027012206?xsec_token=ABc2hOAUpW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>卡司特高端留学</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2024QS商科硕士专业排名已出炉，摘录了金融、管理、商业分析、市场营销四大专业，给大家简单...</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>http://sns-webpic-qc.xhscdn.com/202412050737/4...</td>\n",
       "      <td>728.0</td>\n",
       "      <td>1</td>\n",
       "      <td>/65e05d7d000000000400320b?xsec_token=ABeiFCyZZ...</td>\n",
       "      <td>65e05d7d000000000400320b?xsec_token=ABeiFCyZZM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>姜姜说留学</td>\n",
       "      <td>6.0</td>\n",
       "      <td>根据美国劳工统计局的数据，STEM专业带动的工作岗位，其增长速度和薪酬水平均在美国就业市场处...</td>\n",
       "      <td>2024-10-28</td>\n",
       "      <td>http://sns-webpic-qc.xhscdn.com/202412050737/e...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1</td>\n",
       "      <td>/671f9138000000002401960e?xsec_token=ABN-deT_N...</td>\n",
       "      <td>671f9138000000002401960e?xsec_token=ABN-deT_NS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chloe在留学</td>\n",
       "      <td>22.0</td>\n",
       "      <td>🍭因为商科还有些可投递，我就寻思把这个系列给大家持续更出来，最大限度的帮同学们节省时间，选专...</td>\n",
       "      <td>2024-02-14</td>\n",
       "      <td>http://sns-webpic-qc.xhscdn.com/202412050737/d...</td>\n",
       "      <td>680.0</td>\n",
       "      <td>1</td>\n",
       "      <td>/65ccc5c0000000002d0009cd?xsec_token=ABNS3Sab_...</td>\n",
       "      <td>65ccc5c0000000002d0009cd?xsec_token=ABNS3Sab_K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>芋泥学姐</td>\n",
       "      <td>17.0</td>\n",
       "      <td>今天为大家整理了QS2025商科管理专业TOP50榜单，一起来看看吧！ - 👑斯坦福大学商学...</td>\n",
       "      <td>2024-10-26</td>\n",
       "      <td>http://sns-webpic-qc.xhscdn.com/202412050737/5...</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1</td>\n",
       "      <td>/671cd97a000000002401a003?xsec_token=AB0fnW-Eu...</td>\n",
       "      <td>671cd97a000000002401a003?xsec_token=AB0fnW-Euy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Allen的留学情报站</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#留学美国 #美国研究生 #美国研究生申请 #美国研究生留学申请</td>\n",
       "      <td>2024-07-10</td>\n",
       "      <td>http://sns-webpic-qc.xhscdn.com/202412050737/e...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>/668e095e00000000250035b3?xsec_token=ABOiJSK6o...</td>\n",
       "      <td>668e095e00000000250035b3?xsec_token=ABOiJSK6o_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Winnie学姐的英国日记</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10个留学生8个学商科！ \\t 好家伙，🇬🇧英国你直接点名中国学生得了。作为中国学生“扎堆”...</td>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>http://sns-webpic-qc.xhscdn.com/202412050738/e...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>/672caf99000000003c01b666?xsec_token=ABi-WlgaB...</td>\n",
       "      <td>672caf99000000003c01b666?xsec_token=ABi-WlgaBB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rachel学姐🐙</td>\n",
       "      <td>NaN</td>\n",
       "      <td>🌟想读商科又想进名校，但背景不够强？来看看美国名校的泛商科水项目吧！低绩点的同学也有机会冲哦...</td>\n",
       "      <td>2024-10-10</td>\n",
       "      <td>http://sns-webpic-qc.xhscdn.com/202412050738/a...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1</td>\n",
       "      <td>/66bf28200000000005031860?xsec_token=ABT_ZUM5v...</td>\n",
       "      <td>66bf28200000000005031860?xsec_token=ABT_ZUM5vV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>viki学姐硕博留学</td>\n",
       "      <td>NaN</td>\n",
       "      <td>🧮会计学是美国留学的热门选择，作为美国商学院的传统专业方向之一，一直保持着较为稳定的就业需求...</td>\n",
       "      <td>2024-09-28</td>\n",
       "      <td>http://sns-webpic-qc.xhscdn.com/202412050738/4...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>/66f7ddb2000000002c02c8ee?xsec_token=ABtMnnPjX...</td>\n",
       "      <td>66f7ddb2000000002c02c8ee?xsec_token=ABtMnnPjXa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cheese学姐留学指南</td>\n",
       "      <td>36.0</td>\n",
       "      <td>留学的热门专业里，金融类几乎可以算是第一，不少本科学其他类型专业的学生，也会通过在研究生阶段...</td>\n",
       "      <td>2024-03-27</td>\n",
       "      <td>http://sns-webpic-qc.xhscdn.com/202412050738/8...</td>\n",
       "      <td>214.0</td>\n",
       "      <td>1</td>\n",
       "      <td>/6603f2b10000000012033c24?xsec_token=ABALokOeF...</td>\n",
       "      <td>6603f2b10000000012033c24?xsec_token=ABALokOeF0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     author_name  comment_nr  \\\n",
       "0    小红薯63DFCF89         NaN   \n",
       "1        卡司特高端留学        57.0   \n",
       "2          姜姜说留学         6.0   \n",
       "3       Chloe在留学        22.0   \n",
       "4           芋泥学姐        17.0   \n",
       "5    Allen的留学情报站         NaN   \n",
       "6  Winnie学姐的英国日记         5.0   \n",
       "7      Rachel学姐🐙         NaN   \n",
       "8     viki学姐硕博留学         NaN   \n",
       "9   Cheese学姐留学指南        36.0   \n",
       "\n",
       "                                             content datePublished  \\\n",
       "0  留学商科专业选择，关键在于了解自己的兴趣所在，并找到与之匹配的大方向。这样，选校过程就能更加...    2024-07-31   \n",
       "1  2024QS商科硕士专业排名已出炉，摘录了金融、管理、商业分析、市场营销四大专业，给大家简单...    2024-03-20   \n",
       "2  根据美国劳工统计局的数据，STEM专业带动的工作岗位，其增长速度和薪酬水平均在美国就业市场处...    2024-10-28   \n",
       "3  🍭因为商科还有些可投递，我就寻思把这个系列给大家持续更出来，最大限度的帮同学们节省时间，选专...    2024-02-14   \n",
       "4  今天为大家整理了QS2025商科管理专业TOP50榜单，一起来看看吧！ - 👑斯坦福大学商学...    2024-10-26   \n",
       "5                   #留学美国 #美国研究生 #美国研究生申请 #美国研究生留学申请    2024-07-10   \n",
       "6  10个留学生8个学商科！ \\t 好家伙，🇬🇧英国你直接点名中国学生得了。作为中国学生“扎堆”...    2024-11-07   \n",
       "7  🌟想读商科又想进名校，但背景不够强？来看看美国名校的泛商科水项目吧！低绩点的同学也有机会冲哦...    2024-10-10   \n",
       "8  🧮会计学是美国留学的热门选择，作为美国商学院的传统专业方向之一，一直保持着较为稳定的就业需求...    2024-09-28   \n",
       "9  留学的热门专业里，金融类几乎可以算是第一，不少本科学其他类型专业的学生，也会通过在研究生阶段...    2024-03-27   \n",
       "\n",
       "                                              images  like_nr  star_nr  \\\n",
       "0  http://sns-webpic-qc.xhscdn.com/202412050737/a...   1496.0        1   \n",
       "1  http://sns-webpic-qc.xhscdn.com/202412050737/4...    728.0        1   \n",
       "2  http://sns-webpic-qc.xhscdn.com/202412050737/e...     51.0        1   \n",
       "3  http://sns-webpic-qc.xhscdn.com/202412050737/d...    680.0        1   \n",
       "4  http://sns-webpic-qc.xhscdn.com/202412050737/5...    128.0        1   \n",
       "5  http://sns-webpic-qc.xhscdn.com/202412050737/e...     36.0        1   \n",
       "6  http://sns-webpic-qc.xhscdn.com/202412050738/e...     31.0        1   \n",
       "7  http://sns-webpic-qc.xhscdn.com/202412050738/a...     87.0        1   \n",
       "8  http://sns-webpic-qc.xhscdn.com/202412050738/4...     47.0        1   \n",
       "9  http://sns-webpic-qc.xhscdn.com/202412050738/8...    214.0        1   \n",
       "\n",
       "                                                 url  \\\n",
       "0  /66aa25260000000027012206?xsec_token=ABc2hOAUp...   \n",
       "1  /65e05d7d000000000400320b?xsec_token=ABeiFCyZZ...   \n",
       "2  /671f9138000000002401960e?xsec_token=ABN-deT_N...   \n",
       "3  /65ccc5c0000000002d0009cd?xsec_token=ABNS3Sab_...   \n",
       "4  /671cd97a000000002401a003?xsec_token=AB0fnW-Eu...   \n",
       "5  /668e095e00000000250035b3?xsec_token=ABOiJSK6o...   \n",
       "6  /672caf99000000003c01b666?xsec_token=ABi-WlgaB...   \n",
       "7  /66bf28200000000005031860?xsec_token=ABT_ZUM5v...   \n",
       "8  /66f7ddb2000000002c02c8ee?xsec_token=ABtMnnPjX...   \n",
       "9  /6603f2b10000000012033c24?xsec_token=ABALokOeF...   \n",
       "\n",
       "                                            user_url  \n",
       "0  66aa25260000000027012206?xsec_token=ABc2hOAUpW...  \n",
       "1  65e05d7d000000000400320b?xsec_token=ABeiFCyZZM...  \n",
       "2  671f9138000000002401960e?xsec_token=ABN-deT_NS...  \n",
       "3  65ccc5c0000000002d0009cd?xsec_token=ABNS3Sab_K...  \n",
       "4  671cd97a000000002401a003?xsec_token=AB0fnW-Euy...  \n",
       "5  668e095e00000000250035b3?xsec_token=ABOiJSK6o_...  \n",
       "6  672caf99000000003c01b666?xsec_token=ABi-WlgaBB...  \n",
       "7  66bf28200000000005031860?xsec_token=ABT_ZUM5vV...  \n",
       "8  66f7ddb2000000002c02c8ee?xsec_token=ABtMnnPjXa...  \n",
       "9  6603f2b10000000012033c24?xsec_token=ABALokOeF0...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已保存到 'scraped_data.csv'\n"
     ]
    }
   ],
   "source": [
    "dic={\n",
    "    # \"author_collect_nr\": authorCollectNr_list,# 作者获赞与收藏数量\n",
    "    # \"author_fans_nr\": authorFansNr_list,# 粉丝数量\n",
    "    \"author_name\": authorName_list,# 作者名字\n",
    "    # \"author_note_nr\": authorNoteNr_list,# 作者笔记数量\n",
    "    \"comment_nr\": commentNr_list,# 笔记评论数量\n",
    "    \"content\": content_list,# 笔记内容\n",
    "    \"datePublished\": datePublished_list,# 笔记发布日期\n",
    "    \"images\": images_list,# 笔记封面图片\n",
    "    \"like_nr\": likeNr_list,# 笔记获赞数量\n",
    "    \"star_nr\" : starNr_list,\n",
    "    \"url\": URL_list,# 笔记URL\n",
    "    \"user_url\": userURL_list# 作者URL\n",
    "    }\n",
    "\n",
    "df = pd.DataFrame.from_dict(dic)\n",
    "df = df[~df.duplicated(keep='first')]# 检索并删除所有属性值都相同的行,即保留第一次出现的行，删除后续的重复行\n",
    "print(\"删除\", num-len(df), \"行重复行后剩余\", len(df), \"行。\")\n",
    "print('检查时间:',time.ctime())\n",
    "display(df.head(10))\n",
    "df.to_csv('scraped_data.csv', encoding='utf-8-sig')\n",
    "print(\"数据已保存到 'scraped_data.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xiaoliu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
